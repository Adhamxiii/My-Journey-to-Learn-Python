{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Science Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp_ms</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [{'screen_na...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 1024, 'h'...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401759387648</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': \".@krollbondratin...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @bpolitics: .@krollbondrating's Christopher...</td>\n",
       "      <td>1459294817758</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 3600, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [{'text': 'cruzsexscandal', 'indi...</td>\n",
       "      <td>{'media': [{'sizes': {'large': {'w': 500, 'h':...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960401977319424</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'retweeted': False, 'text': '@dmartosko Cruz ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>RT @HeidiAlpine: @dmartosko Cruz video found.....</td>\n",
       "      <td>1459294817810</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': None, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Mar 29 23:40:17 +0000 2016</td>\n",
       "      <td>{'hashtags': [], 'user_mentions': [], 'symbols...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714960402426236928</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://www.facebook.com/twitter\" rel=...</td>\n",
       "      <td>Njihuni me ZonjÃ«n Trump !!! | Ekskluzive http...</td>\n",
       "      <td>1459294817917</td>\n",
       "      <td>False</td>\n",
       "      <td>{'utc_offset': 7200, 'profile_image_url_https'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "1           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "2           NaN          NaN  Tue Mar 29 23:40:17 +0000 2016   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'user_mentions': [{'screen_na...   \n",
       "1  {'hashtags': [{'text': 'cruzsexscandal', 'indi...   \n",
       "2  {'hashtags': [], 'user_mentions': [], 'symbols...   \n",
       "\n",
       "                                   extended_entities  favorite_count  \\\n",
       "0  {'media': [{'sizes': {'large': {'w': 1024, 'h'...               0   \n",
       "1  {'media': [{'sizes': {'large': {'w': 500, 'h':...               0   \n",
       "2                                                NaN               0   \n",
       "\n",
       "   favorited filter_level  geo                  id  ...  quoted_status_id  \\\n",
       "0      False          low  NaN  714960401759387648  ...               NaN   \n",
       "1      False          low  NaN  714960401977319424  ...               NaN   \n",
       "2      False          low  NaN  714960402426236928  ...               NaN   \n",
       "\n",
       "  quoted_status_id_str  retweet_count  retweeted  \\\n",
       "0                  NaN              0      False   \n",
       "1                  NaN              0      False   \n",
       "2                  NaN              0      False   \n",
       "\n",
       "                                    retweeted_status  \\\n",
       "0  {'retweeted': False, 'text': \".@krollbondratin...   \n",
       "1  {'retweeted': False, 'text': '@dmartosko Cruz ...   \n",
       "2                                                NaN   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...   \n",
       "2  <a href=\"http://www.facebook.com/twitter\" rel=...   \n",
       "\n",
       "                                                text   timestamp_ms truncated  \\\n",
       "0  RT @bpolitics: .@krollbondrating's Christopher...  1459294817758     False   \n",
       "1  RT @HeidiAlpine: @dmartosko Cruz video found.....  1459294817810     False   \n",
       "2  Njihuni me ZonjÃ«n Trump !!! | Ekskluzive http...  1459294817917     False   \n",
       "\n",
       "                                                user  \n",
       "0  {'utc_offset': 3600, 'profile_image_url_https'...  \n",
       "1  {'utc_offset': None, 'profile_image_url_https'...  \n",
       "2  {'utc_offset': 7200, 'profile_image_url_https'...  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/tweets.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Writing your own functions\n",
    "User-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n"
     ]
    }
   ],
   "source": [
    "def shout(word):\n",
    "    shout_word = word + '!!!'\n",
    "    return(shout_word)\n",
    "\n",
    "yell = shout(\"congratulations\")\n",
    "print(yell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple parameters and return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations you!!!\n"
     ]
    }
   ],
   "source": [
    "def shout(word1, word2):\n",
    "    return (word1 + \" \" + word2 + \"!!!\")\n",
    "\n",
    "yell = shout(\"congratulations\", \"you\")\n",
    "print(yell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "congratulations!!!\n",
      "you!!!\n"
     ]
    }
   ],
   "source": [
    "def shout_all(word1, word2): \n",
    "    shout1 = word1 + '!!!'\n",
    "    shout2 = word2 + '!!!'\n",
    "    shout_words = (shout1,shout2)\n",
    "    return shout_words\n",
    "\n",
    "yell1, yell2 = shout_all('congratulations','you')\n",
    "print(yell1)\n",
    "print(yell2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "def count_entries(df, col_name):\n",
    "    langs_count = {}\n",
    "    col = df[col_name]\n",
    "    for entry in col:\n",
    "        if entry in langs_count.keys():\n",
    "            langs_count[entry] += 1\n",
    "        else:\n",
    "            langs_count[entry] = 1\n",
    "    return langs_count\n",
    "\n",
    "result = count_entries(df,'lang')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Default arguments, variable-length arguments and scope\n",
    "Scope and user-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teen titans\n",
      "justice league\n"
     ]
    }
   ],
   "source": [
    "team = \"teen titans\"\n",
    "\n",
    "\n",
    "def change_team():\n",
    "    global team\n",
    "    team = \"justice league\"\n",
    "\n",
    "\n",
    "print(team)\n",
    "change_team()\n",
    "print(team)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('congratulations!!!', 'you!!!', 'me!!!')\n"
     ]
    }
   ],
   "source": [
    "def three_shouts(word1, word2, word3):\n",
    "    def inner(word):\n",
    "        return word + \"!!!\"\n",
    "\n",
    "    return inner(word1), inner(word2), inner(word3)\n",
    "\n",
    "print(three_shouts(\"congratulations\", \"you\", \"me\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiHi\n",
      "HiHi!!!\n"
     ]
    }
   ],
   "source": [
    "def echo_shout(word):\n",
    "    echo_word = word + word\n",
    "    print(echo_word)\n",
    "\n",
    "    def shout():\n",
    "        nonlocal echo_word\n",
    "        echo_word = echo_word + \"!!!\"\n",
    "\n",
    "    shout()\n",
    "    print(echo_word)\n",
    "\n",
    "echo_shout(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default and flexible arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEYHEYHEYHEYHEY!!!\n",
      "BYE!!!\n"
     ]
    }
   ],
   "source": [
    "def shout_echo(word1, echo=1, intense=False):\n",
    "    echo_word = word1 * echo\n",
    "    if intense:\n",
    "        echo_word_new = echo_word.upper() + \"!!!\"\n",
    "    else:\n",
    "        echo_word_new = echo_word + \"!!!\"\n",
    "    return echo_word_new\n",
    "    \n",
    "with_big_echo = shout_echo(\"Hey\", 5, True)\n",
    "big_no_echo = shout_echo(\"Bye\", intense=True)\n",
    "\n",
    "print(with_big_echo)\n",
    "print(big_no_echo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word\n",
      "onetwothree\n"
     ]
    }
   ],
   "source": [
    "def gibberish(*args):\n",
    "    hodgepodge = ''\n",
    "    for word in args:\n",
    "        hodgepodge += word\n",
    "    return hodgepodge\n",
    "\n",
    "one_word = gibberish(\"word\")\n",
    "many_words = gibberish(\"one\", \"two\", \"three\")\n",
    "\n",
    "print(one_word)\n",
    "print(many_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: Adham\n",
      "age: 23\n",
      "job: programmer\n",
      "\n",
      "END REPORT\n",
      "\n",
      "BEGIN: REPORT\n",
      "\n",
      "name: Aya\n",
      "job: teacher\n",
      "\n",
      "END REPORT\n"
     ]
    }
   ],
   "source": [
    "def report_status(**kwargs):\n",
    "    print(\"\\nBEGIN: REPORT\\n\")\n",
    "    for key, value in kwargs.items():\n",
    "        print(key + \": \" + value)\n",
    "    print(\"\\nEND REPORT\")\n",
    "\n",
    "report_status(name='Adham', age='23', job=\"programmer\")\n",
    "report_status(name='Aya', job=\"teacher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n",
      "{'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">PlumeÂ forÂ Android</a>': 1}\n"
     ]
    }
   ],
   "source": [
    "def count_entries(df, col_name='lang'):\n",
    "    cols_count = {}\n",
    "    col = df[col_name]\n",
    "\n",
    "    for entry in col:\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "    return cols_count\n",
    "\n",
    "result1 = count_entries(df)\n",
    "return2 = count_entries(df, 'source')\n",
    "\n",
    "print(result1)\n",
    "print(return2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n",
      "----------\n",
      "{'en': 97, 'et': 1, 'und': 2, '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">PlumeÂ forÂ Android</a>': 1}\n"
     ]
    }
   ],
   "source": [
    "def count_entries(df, *args):\n",
    "    cols_count = {}\n",
    "    for col_name in args:\n",
    "        col = df[col_name]\n",
    "        for entry in col:\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "    return cols_count\n",
    "\n",
    "result1 = count_entries(df, 'lang')\n",
    "result2 = count_entries(df, 'lang', 'source')\n",
    "\n",
    "print(result1)\n",
    "print('----------')\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lambda functions and error-handling\n",
    "Lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HI!!!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_bangs = (lambda a: a + '!!!')\n",
    "add_bangs(\"HI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HeyHeyHeyHeyHey'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echo_word = (lambda word, echo: word * echo)\n",
    "echo_word(\"Hey\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<map object at 0x000001D50F8ED690>\n",
      "[4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "def square(n):\n",
    "    return n * n\n",
    "my_list = [2,3,4,5,6,7,8,9]\n",
    "update_list = map(square, my_list)\n",
    "print(update_list)\n",
    "print(list(update_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protect!!!', 'act!!!', 'patrons!!!', 'lawful!!!']\n"
     ]
    }
   ],
   "source": [
    "spells = ['protect', 'act', 'patrons', 'lawful']\n",
    "shout_spells = map(lambda item: item + '!!!', spells)\n",
    "print(list(shout_spells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samwise', 'aragorn', 'boromir', 'legolas', 'gandalf']\n"
     ]
    }
   ],
   "source": [
    "fellowship = [\n",
    "    \"frodo\",\n",
    "    \"samwise\",\n",
    "    \"merry\",\n",
    "    \"pippin\",\n",
    "    \"aragorn\",\n",
    "    \"boromir\",\n",
    "    \"legolas\",\n",
    "    \"gimli\",\n",
    "    \"gandalf\",\n",
    "]\n",
    "result = filter(lambda a: len(a)>6 , fellowship)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robbsansaaryabrandonrickon\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "stark = ['robb', 'sansa', 'arya', 'brandon', 'rickon']\n",
    "result = reduce(lambda item1, item2: item1 + item2, stark)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word1 must be a string and echo must be a number.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shout_echo(word1 , echo=1):\n",
    "    echo_word = ''\n",
    "    shout_words = ''\n",
    "    try:\n",
    "        echo_word = word1 * echo\n",
    "        shout_words = echo_word + '!!!'\n",
    "    except:\n",
    "        print('word1 must be a string and echo must be a number.')\n",
    "    return shout_words\n",
    "\n",
    "shout_echo('particle', echo='accelerator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'particleparticleparticleparticleparticle!!!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shout_echo(word1, echo=1):\n",
    "    if echo<0:\n",
    "        raise ValueError('echo must be greater than 0')\n",
    "    \n",
    "    echo_word = word1 * echo\n",
    "    shout_words = echo_word + '!!!'\n",
    "    return shout_words\n",
    "\n",
    "shout_echo('particle', echo=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @bpolitics: .@krollbondrating's Christopher Whalen says Clinton is the weakest Dem candidate in 50 years https://t.co/pLk7rvoRSn https:/â€¦\n",
      "RT @HeidiAlpine: @dmartosko Cruz video found.....racing from the scene.... #cruzsexscandal https://t.co/zuAPZfQDk3\n",
      "RT @AlanLohner: The anti-American D.C. elites despise Trump for his America-first foreign policy. Trump threatens their gravy train. https:â€¦\n",
      "RT @BIackPplTweets: Young Donald trump meets his neighbor  https://t.co/RFlu17Z1eE\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @HouseCracka: 29,000+ PEOPLE WATCHING TRUMP LIVE ON ONE STREAM!!!\n",
      "\n",
      "https://t.co/7QCFz9ehNe\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @trumpresearch: @WaitingInBagdad @thehill Trump supporters have selective amnisia.\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  httpsâ€¦\n",
      "RT @urfavandtrump: RT for Brendon Urie\n",
      "Fav for Donald Trump https://t.co/PZ5vS94lOg\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/â€¦\n",
      "RT @Pjw20161951: NO KIDDING: #SleazyDonald just attacked Scott Walker for NOT RAISING TAXES in WI! #LyinTrump\n",
      "#NeverTrump  #CruzCrew  httpsâ€¦\n",
      "RT @trapgrampa: This is how I see #Trump every time he speaks. https://t.co/fYSiHNS0nT\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearlyâ€¦\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET httpsâ€¦\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/â€¦\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://â€¦\n",
      "RT @paulbenedict7: How #Trump Sacks RINO Strongholds by Hitting Positions Held by Dems and GOP https://t.co/D7ulnAJhis   #tcot #PJNET httpsâ€¦\n",
      "RT @DRUDGE_REPORT: VIDEO:  Trump emotional moment with Former Miss Wisconsin who has terminal illness... https://t.co/qt06aG9inT\n",
      "RT @DennisApgar: Thank God I seen Trump at first stop in Wisconsin media doesn't know how great he is, advice watch live streaming https://â€¦\n",
      "RT @mitchellvii: So let me get this straight.  Any reporter can assault Mr Trump at any time and Corey can do nothing?  Michelle is clearlyâ€¦\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9Nâ€¦\n",
      "RT @Norsu2: Nightmare WI poll for Ted Cruz has Kasich surging: Trump 29, Kasich 27, Cruz 25. https://t.co/lJsgbLYY1P #NeverTrump\n",
      "RT @thehill: WATCH: Protester pepper-sprayed point blank at Trump rally https://t.co/B5f65Al9ld https://t.co/skAfByXuQc\n",
      "RT @sciam: Trump's idiosyncratic patterns of speech are why people tend either to love or hate him https://t.co/QXwquVgs3c https://t.co/P9Nâ€¦\n",
      "RT @ggreenwald: The media spent all day claiming @SusanSarandon said she might vote for Trump. A total fabrication, but whatever... https:/â€¦\n",
      "RT @DebbieStout5: Wow! Last I checked it was just 12 points &amp; that wasn't more than a day ago. Oh boy Trump ppl might want to rethinkðŸ¤” httpâ€¦\n",
      "RT @tyleroakley: i'm a messy bitch, but at least i'm not voting for trump\n",
      "RT @vandives: Trump supporters r tired of justice NOT being served. There's no justice anymore. Hardworking Americans get screwed. That's nâ€¦\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "RT @AP: BREAKING: Trump vows to stand by campaign manager charged with battery, says he does not discard people.\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "RT @urfavandtrump: RT for Jerrie (Little Mix)\n",
      "Fav for Donald Trump https://t.co/nEVxElW6iG\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNNâ€¦\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will nâ€¦\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "RT @NoahCRothman: When Walker was fighting for reforms, Trump was defending unions and collective bargaining privileges https://t.co/e1UWNNâ€¦\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:â€¦\n",
      "RT @AIIAmericanGirI: VIDEO=&gt; Anti-Trump Protester SLUGS Elderly Trump Supporter in the Face\n",
      "https://t.co/GeEryMDuDY\n",
      "RT @RedheadAndRight: Report: Secret Service Says Michelle Fields Touched Trump https://t.co/c5c2sD8VO2\n",
      "\n",
      "This is the only article you will nâ€¦\n",
      "RT @JusticeRanger1: @realDonaldTrump @Pudingtane @DanScavino @GOP @infowars @EricTrump \n",
      "URGENT PUBLIC TRUMP ALERT:\n",
      "COVERT KILL MEANS https:â€¦\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation Pâ€¦\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educatâ€¦\n",
      "RT @Schneider_CM: Trump says nobody had ever heard of executive orders before Obama started signing them. Never heard of the Emancipation Pâ€¦\n",
      "RT @DonaldsAngel: Former Ms. WI just said that she is terminally ill but because of Trump pageant, her 7 yr. old son has his college educatâ€¦\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @Tâ€¦\n",
      "RT @RonBasler1: @DavidWhitDennis @realDonaldTrump @tedcruz \n",
      "\n",
      "CRUZ SCREWS HOOKERS\n",
      "\n",
      "CRUZ / CLINTON\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/â€¦\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didnâ€™t come out of nowhere.\" â€”Hillary\n",
      "httpsâ€¦\n",
      "RT @Dodarey: @DR8801 @SykesCharlie Charlie, let's see you get a straight \"yes\" or \"no\" answer from Cruz a/b being unfaithful to his wife @Tâ€¦\n",
      "RT @HillaryClinton: \"Every day, another Republican bemoans the rise of Donald Trump... but [he] didnâ€™t come out of nowhere.\" â€”Hillary\n",
      "httpsâ€¦\n",
      "RT @RockCliffOne: Remember when the idea of a diabolical moron holding the world hostage was an idea for a funny movie? #Trump #GOP https:/â€¦\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating tâ€¦\n",
      "RT @immigrant4trump: @immigrant4trump msm, cable news attacking trump all day, from 8am to 10pm today, then the reruns come on, repeating tâ€¦\n",
      "RT @GlendaJazzey: Donald Trumpâ€™s Campaign Financing Dodge, @rrotunda https://t.co/L8flI4lswG via @VerdictJustia\n",
      "RT @TUSK81: LOUDER FOR THE PEOPLE IN THE BACK https://t.co/hlPVyNLXzx\n",
      "RT @loopzoop: Well...put it back https://t.co/8Yb7BDT5VM\n",
      "RT @claytoncubitt: Stop asking Bernie supporters if theyâ€™ll vote for Hillary against Trump. We got a plan to beat Trump already. Called Berâ€¦\n",
      "RT @akaMaude13: Seriously can't make this up. What a joke. #NeverTrump  https://t.co/JkTx6mdRgC\n"
     ]
    }
   ],
   "source": [
    "result = filter(lambda x: x[0:2]==\"RT\", df['text'])\n",
    "res_list = list(result)\n",
    "for tween in res_list:\n",
    "    print(tween)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "def count_entries(df, col_name='lang'):\n",
    "    cols_count = {}\n",
    "    try:\n",
    "        col = df[col_name]\n",
    "        for entry in col:\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "\n",
    "        return cols_count\n",
    "    except:\n",
    "        print('The DataFrame does not have a ' + col_name + ' column')\n",
    "\n",
    "result = count_entries(df, 'lang')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "def count_entries(df, col_name='lang'):\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError('The DataFrame does not have a ' + col_name + ' column')\n",
    "    cols_count = {}\n",
    "    col = df[col_name]\n",
    "\n",
    "    for entry in col:\n",
    "        if entry in cols_count.keys():\n",
    "            cols_count[entry] += 1\n",
    "        else:\n",
    "            cols_count[entry] = 1\n",
    "    return cols_count\n",
    "\n",
    "result = count_entries(df, col_name='lang')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "def count_entries(df, col_name=\"lang\"):\n",
    "    if col_name not in df.columns:\n",
    "        raise ValueError(\"The DataFrame does not have a \" + col_name + \" column\")\n",
    "    cols_count = {}\n",
    "\n",
    "    try:\n",
    "        for entry in df[col_name]:\n",
    "            if entry in cols_count.keys():\n",
    "                cols_count[entry] += 1\n",
    "            else:\n",
    "                cols_count[entry] = 1\n",
    "        return cols_count\n",
    "    except:\n",
    "        print(\"The DataFrame does not have a \" + col_name + \" column\")\n",
    "\n",
    "\n",
    "result = count_entries(df, col_name=\"lang\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Urban population (% of total)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>1960</td>\n",
       "      <td>92495902.0</td>\n",
       "      <td>31.285384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caribbean small states</td>\n",
       "      <td>CSS</td>\n",
       "      <td>1960</td>\n",
       "      <td>4190810.0</td>\n",
       "      <td>31.597490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Central Europe and the Baltics</td>\n",
       "      <td>CEB</td>\n",
       "      <td>1960</td>\n",
       "      <td>91401583.0</td>\n",
       "      <td>44.507921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CountryName CountryCode  Year  Total Population  \\\n",
       "0                      Arab World         ARB  1960        92495902.0   \n",
       "1          Caribbean small states         CSS  1960         4190810.0   \n",
       "2  Central Europe and the Baltics         CEB  1960        91401583.0   \n",
       "\n",
       "   Urban population (% of total)  \n",
       "0                      31.285384  \n",
       "1                      31.597490  \n",
       "2                      44.507921  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_blank = pd.read_csv('../data/world_bank.csv')\n",
    "world_blank.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using iterators in PythonLand\n",
    "Introduction to iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** jay garrick\n",
      "** barry allen\n",
      "** wally west\n",
      "** bart allen\n",
      "jay garrick\n",
      "barry allen\n",
      "wally west\n"
     ]
    }
   ],
   "source": [
    "flash = [\"jay garrick\", \"barry allen\", \"wally west\", \"bart allen\"]\n",
    "\n",
    "for element in flash:\n",
    "    print(\"**\", element)\n",
    "\n",
    "superhero = iter(flash)\n",
    "\n",
    "print(next(superhero))\n",
    "print(next(superhero))\n",
    "print(next(superhero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0\n",
      "- 1\n",
      "- 2\n",
      "0\n",
      "1\n",
      "2\n",
      "** 0\n",
      "** 1\n",
      "** 2\n",
      "** 3\n",
      "** 4\n"
     ]
    }
   ],
   "source": [
    "small_value = iter(range(3))\n",
    "print(\"-\", next(small_value))\n",
    "print(\"-\", next(small_value))\n",
    "print(\"-\", next(small_value))\n",
    "\n",
    "for num in range(3):\n",
    "    print(num)\n",
    "\n",
    "googol = iter(range(10**100))\n",
    "print(\"**\", next(googol))\n",
    "print(\"**\", next(googol))\n",
    "print(\"**\", next(googol))\n",
    "print(\"**\", next(googol))\n",
    "print(\"**\", next(googol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D a t a\n"
     ]
    }
   ],
   "source": [
    "word = 'Data'\n",
    "it = iter(word)\n",
    "print(*it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hugo bowne-anderson\n",
      "francis castro\n"
     ]
    }
   ],
   "source": [
    "pythonistas = {'hugo': 'bowne-anderson', 'francis': 'castro'}\n",
    "for key, value in pythonistas.items():    \n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'charles xavier'), (1, 'bobby drake'), (2, 'kurt wagner'), (3, 'max eisenhardt'), (4, 'kitty pryde')]\n",
      "> 0 charles xavier\n",
      "> 1 bobby drake\n",
      "> 2 kurt wagner\n",
      "> 3 max eisenhardt\n",
      "> 4 kitty pryde\n",
      "1 charles xavier\n",
      "2 bobby drake\n",
      "3 kurt wagner\n",
      "4 max eisenhardt\n",
      "5 kitty pryde\n"
     ]
    }
   ],
   "source": [
    "mutants = [\n",
    "    \"charles xavier\",\n",
    "    \"bobby drake\",\n",
    "    \"kurt wagner\",\n",
    "    \"max eisenhardt\",\n",
    "    \"kitty pryde\",\n",
    "]\n",
    "\n",
    "aliases = [\"prof x\", \"iceman\", \"nightcrawler\", \"magneto\", \"shadowcat\"]\n",
    "powers = [\n",
    "    \"telepathy\",\n",
    "    \"thermokinesis\",\n",
    "    \"teleportation\",\n",
    "    \"magnetokinesis\",\n",
    "    \"intangibility\",\n",
    "]\n",
    "\n",
    "mutant_list = list(enumerate(mutants))\n",
    "print(mutant_list)\n",
    "\n",
    "for index, value in enumerate(mutants):\n",
    "    print(\">\", index, value)\n",
    "\n",
    "for index, value in enumerate(mutants, 1):\n",
    "    print(index, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('charles xavier', 'prof x', 'telepathy'), ('bobby drake', 'iceman', 'thermokinesis'), ('kurt wagner', 'nightcrawler', 'teleportation'), ('max eisenhardt', 'magneto', 'magnetokinesis'), ('kitty pryde', 'shadowcat', 'intangibility')]\n",
      "<zip object at 0x000001D50F90FD00>\n",
      "charles xavier prof x telepathy\n",
      "bobby drake iceman thermokinesis\n",
      "kurt wagner nightcrawler teleportation\n",
      "max eisenhardt magneto magnetokinesis\n",
      "kitty pryde shadowcat intangibility\n"
     ]
    }
   ],
   "source": [
    "mutant_data = list(zip(mutants,aliases,powers))\n",
    "print(mutant_data)\n",
    "\n",
    "mutant_zip = zip(mutants,aliases,powers)\n",
    "print(mutant_zip)\n",
    "\n",
    "for value1, value2, value3 in mutant_zip:\n",
    "    print(value1, value2, value3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('charles xavier', 'telepathy') ('bobby drake', 'thermokinesis') ('kurt wagner', 'teleportation') ('max eisenhardt', 'magnetokinesis') ('kitty pryde', 'intangibility')\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z1 = zip(mutants, powers)\n",
    "print(*z1)\n",
    "\n",
    "z1 = zip(mutants, powers)\n",
    "result1, result2 = zip(*z1)\n",
    "print(result1 == mutants)\n",
    "print(result2 == powers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using iterators to load large files into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 97, 'et': 1, 'und': 2}\n"
     ]
    }
   ],
   "source": [
    "def count_entries(csv_file, c_size, colname):\n",
    "    counts_dict = {}\n",
    "\n",
    "    for chunk in pd.read_csv(csv_file, chunksize=c_size):\n",
    "        for entry in chunk[colname]:\n",
    "            if entry in counts_dict.keys():\n",
    "                counts_dict[entry] += 1\n",
    "            else:\n",
    "                counts_dict[entry] = 1\n",
    "    return counts_dict\n",
    "\n",
    "result = count_entries('../data/tweets.csv', 10, 'lang')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. List comprehensions and generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE -----\n",
      "[13, 9, 22, 4, 17] \n",
      "\n",
      "AFTER -----\n",
      "[13, 9, 22, 4, 17]\n"
     ]
    }
   ],
   "source": [
    "nums = [12, 8, 21, 3, 16]\n",
    "new_nums = []\n",
    "for num in nums:\n",
    "    new_nums.append(num + 1)\n",
    "\n",
    "print(\"BEFORE -----\")\n",
    "print(new_nums, '\\n')\n",
    "\n",
    "new_nums = [num + 1 for num in nums]\n",
    "print(\"AFTER -----\")\n",
    "print(new_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i**2 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "matrix = [[col for col in range(5)] for row in range(5)]\n",
    "for row in matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced comprehensions\n",
    "\n",
    "[ output expression for iterator variable in iterable if predicate expression ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['samwise', 'aragorn', 'legolas', 'boromir']\n"
     ]
    }
   ],
   "source": [
    "fellowship = [\"frodo\", \"samwise\", \"merry\", \"aragorn\", \"legolas\", \"boromir\", \"gimli\"]\n",
    "new_fellowship = [member for member in fellowship if len(member) >= 7]\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 4, 0, 16, 0, 36, 0, 64, 0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[num ** 2 if num % 2 == 0 else 0 for num in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'samwise', '', 'aragorn', 'legolas', 'boromir', '']\n"
     ]
    }
   ],
   "source": [
    "new_fellowship = [member if len(member) >= 7 else '' for member in fellowship]\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frodo': 5, 'samwise': 7, 'merry': 5, 'aragorn': 7, 'legolas': 7, 'boromir': 7, 'gimli': 5}\n"
     ]
    }
   ],
   "source": [
    "new_fellowship = {member : len(member) for member in fellowship}\n",
    "print(new_fellowship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to generator expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[num ** 2 for num in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 0\n",
      "- 1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "result = (num for num in range(11))\n",
    "\n",
    "print(\"-\", next(result))\n",
    "print(\"-\", next(result))\n",
    "\n",
    "for num in result:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "lengths = (len(person) for person in lannister)\n",
    "for value in lengths:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']\n",
    "\n",
    "def get_lenths(inpput_list):\n",
    "    for person in inpput_list:\n",
    "        yield len(person)\n",
    "\n",
    "for value in get_lenths(lannister):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping up comprehensions and generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
     ]
    }
   ],
   "source": [
    "tweet_time = df['created_at']\n",
    "\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time]\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
     ]
    }
   ],
   "source": [
    "tweet_time = df['created_at']\n",
    "\n",
    "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
    "print(tweet_clock_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bringing it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['CountryName','CountryCode', 'IndicatorName', 'IndicatorCode', 'Year', 'Value']\n",
    "row_vals = ['Arab World','ARB', 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'SP.ADO.TFRT',\n",
    " '1960','133.56090740552298']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "def lists2dic(list1, list2):\n",
    "    zipped_lists = zip(list1, list2)\n",
    "    return dict(zipped_lists)\n",
    "\n",
    "result = lists2dic(feature_names, row_vals)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_lists = [['Arab World',\n",
    "  'ARB',\n",
    "  'Adolescent fertility rate (births per 1,000 women ages 15-19)',\n",
    "  'SP.ADO.TFRT',\n",
    "  '1960',\n",
    "  '133.56090740552298'],\n",
    " ['Arab World',\n",
    "  'ARB',\n",
    "  'Age dependency ratio (% of working-age population)',\n",
    "  'SP.POP.DPND',\n",
    "  '1960',\n",
    "  '87.7976011532547'],\n",
    " ['Arab World',\n",
    "  'ARB',\n",
    "  'Age dependency ratio, old (% of working-age population)',\n",
    "  'SP.POP.DPND.OL',\n",
    "  '1960',\n",
    "  '6.634579191565161'],\n",
    " ['Arab World',\n",
    "  'ARB',\n",
    "  'Age dependency ratio, young (% of working-age population)',\n",
    "  'SP.POP.DPND.YG',\n",
    "  '1960',\n",
    "  '81.02332950839141']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n",
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Age dependency ratio (% of working-age population)', 'IndicatorCode': 'SP.POP.DPND', 'Year': '1960', 'Value': '87.7976011532547'}\n"
     ]
    }
   ],
   "source": [
    "list_of_dicts = [lists2dic(feature_names, row) for row in row_lists]\n",
    "print(list_of_dicts[0])\n",
    "print(list_of_dicts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountryName</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>IndicatorName</th>\n",
       "      <th>IndicatorCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>1960</td>\n",
       "      <td>133.56090740552298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Age dependency ratio (% of working-age populat...</td>\n",
       "      <td>SP.POP.DPND</td>\n",
       "      <td>1960</td>\n",
       "      <td>87.7976011532547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Age dependency ratio, old (% of working-age po...</td>\n",
       "      <td>SP.POP.DPND.OL</td>\n",
       "      <td>1960</td>\n",
       "      <td>6.634579191565161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>Age dependency ratio, young (% of working-age ...</td>\n",
       "      <td>SP.POP.DPND.YG</td>\n",
       "      <td>1960</td>\n",
       "      <td>81.02332950839141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CountryName CountryCode                                      IndicatorName  \\\n",
       "0  Arab World         ARB  Adolescent fertility rate (births per 1,000 wo...   \n",
       "1  Arab World         ARB  Age dependency ratio (% of working-age populat...   \n",
       "2  Arab World         ARB  Age dependency ratio, old (% of working-age po...   \n",
       "3  Arab World         ARB  Age dependency ratio, young (% of working-age ...   \n",
       "\n",
       "    IndicatorCode  Year               Value  \n",
       "0     SP.ADO.TFRT  1960  133.56090740552298  \n",
       "1     SP.POP.DPND  1960    87.7976011532547  \n",
       "2  SP.POP.DPND.OL  1960   6.634579191565161  \n",
       "3  SP.POP.DPND.YG  1960   81.02332950839141  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list_of_dicts)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Python generators for streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Arab World': 1,\n",
       " 'Caribbean small states': 1,\n",
       " 'Central Europe and the Baltics': 1,\n",
       " 'East Asia & Pacific (all income levels)': 1,\n",
       " 'East Asia & Pacific (developing only)': 1,\n",
       " 'Euro area': 1,\n",
       " 'Europe & Central Asia (all income levels)': 1,\n",
       " 'Europe & Central Asia (developing only)': 1,\n",
       " 'European Union': 1,\n",
       " 'Fragile and conflict affected situations': 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/world_bank.csv') as file:\n",
    "    file.readline()\n",
    "    counts_dict = {}\n",
    "\n",
    "    for j in range(10):\n",
    "        line = file.readline().split(',')\n",
    "        first_col = line[0]\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryName,CountryCode,Year,Total Population,Urban population (% of total)\n",
      "\n",
      "Arab World,ARB,1960,92495902.0,31.285384211605397\n",
      "\n",
      "Caribbean small states,CSS,1960,4190810.0,31.5974898513652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_large_file(file_object):\n",
    "    while True:\n",
    "        data = file_object.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n",
    "\n",
    "with open('../data/world_bank.csv') as file:\n",
    "    gen_file = read_large_file(file)\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CountryName': 1,\n",
       " 'Arab World': 55,\n",
       " 'Caribbean small states': 55,\n",
       " 'Central Europe and the Baltics': 55,\n",
       " 'East Asia & Pacific (all income levels)': 55,\n",
       " 'East Asia & Pacific (developing only)': 55,\n",
       " 'Euro area': 55,\n",
       " 'Europe & Central Asia (all income levels)': 55,\n",
       " 'Europe & Central Asia (developing only)': 55,\n",
       " 'European Union': 55,\n",
       " 'Fragile and conflict affected situations': 55,\n",
       " 'Heavily indebted poor countries (HIPC)': 55,\n",
       " 'High income': 55,\n",
       " 'High income: nonOECD': 55,\n",
       " 'High income: OECD': 55,\n",
       " 'Latin America & Caribbean (all income levels)': 55,\n",
       " 'Latin America & Caribbean (developing only)': 55,\n",
       " 'Least developed countries: UN classification': 55,\n",
       " 'Low & middle income': 55,\n",
       " 'Low income': 55,\n",
       " 'Lower middle income': 55,\n",
       " 'Middle East & North Africa (all income levels)': 55,\n",
       " 'Middle East & North Africa (developing only)': 55,\n",
       " 'Middle income': 55,\n",
       " 'North America': 55,\n",
       " 'OECD members': 55,\n",
       " 'Other small states': 55,\n",
       " 'Pacific island small states': 55,\n",
       " 'Small states': 55,\n",
       " 'South Asia': 55,\n",
       " 'Sub-Saharan Africa (all income levels)': 55,\n",
       " 'Sub-Saharan Africa (developing only)': 55,\n",
       " 'Upper middle income': 55,\n",
       " 'World': 55,\n",
       " 'Afghanistan': 55,\n",
       " 'Albania': 55,\n",
       " 'Algeria': 55,\n",
       " 'American Samoa': 55,\n",
       " 'Andorra': 55,\n",
       " 'Angola': 55,\n",
       " 'Antigua and Barbuda': 55,\n",
       " 'Argentina': 55,\n",
       " 'Armenia': 55,\n",
       " 'Aruba': 55,\n",
       " 'Australia': 55,\n",
       " 'Austria': 55,\n",
       " 'Azerbaijan': 55,\n",
       " '\"Bahamas': 55,\n",
       " 'Bahrain': 55,\n",
       " 'Bangladesh': 55,\n",
       " 'Barbados': 55,\n",
       " 'Belarus': 55,\n",
       " 'Belgium': 55,\n",
       " 'Belize': 55,\n",
       " 'Benin': 55,\n",
       " 'Bermuda': 55,\n",
       " 'Bhutan': 55,\n",
       " 'Bolivia': 55,\n",
       " 'Bosnia and Herzegovina': 55,\n",
       " 'Botswana': 55,\n",
       " 'Brazil': 55,\n",
       " 'Brunei Darussalam': 55,\n",
       " 'Bulgaria': 55,\n",
       " 'Burkina Faso': 55,\n",
       " 'Burundi': 55,\n",
       " 'Cabo Verde': 55,\n",
       " 'Cambodia': 55,\n",
       " 'Cameroon': 55,\n",
       " 'Canada': 55,\n",
       " 'Cayman Islands': 55,\n",
       " 'Central African Republic': 55,\n",
       " 'Chad': 55,\n",
       " 'Channel Islands': 55,\n",
       " 'Chile': 55,\n",
       " 'China': 55,\n",
       " 'Colombia': 55,\n",
       " 'Comoros': 55,\n",
       " '\"Congo': 110,\n",
       " 'Costa Rica': 55,\n",
       " \"Cote d'Ivoire\": 55,\n",
       " 'Croatia': 55,\n",
       " 'Cuba': 55,\n",
       " 'Curacao': 55,\n",
       " 'Cyprus': 55,\n",
       " 'Czech Republic': 55,\n",
       " 'Denmark': 55,\n",
       " 'Djibouti': 55,\n",
       " 'Dominica': 55,\n",
       " 'Dominican Republic': 55,\n",
       " 'Ecuador': 55,\n",
       " '\"Egypt': 55,\n",
       " 'El Salvador': 55,\n",
       " 'Equatorial Guinea': 55,\n",
       " 'Eritrea': 55,\n",
       " 'Estonia': 55,\n",
       " 'Ethiopia': 55,\n",
       " 'Faeroe Islands': 55,\n",
       " 'Fiji': 55,\n",
       " 'Finland': 55,\n",
       " 'France': 55,\n",
       " 'French Polynesia': 55,\n",
       " 'Gabon': 55,\n",
       " '\"Gambia': 55,\n",
       " 'Georgia': 55,\n",
       " 'Germany': 55,\n",
       " 'Ghana': 55,\n",
       " 'Greece': 55,\n",
       " 'Greenland': 55,\n",
       " 'Grenada': 55,\n",
       " 'Guam': 55,\n",
       " 'Guatemala': 55,\n",
       " 'Guinea': 55,\n",
       " 'Guinea-Bissau': 55,\n",
       " 'Guyana': 55,\n",
       " 'Haiti': 55,\n",
       " 'Honduras': 55,\n",
       " '\"Hong Kong SAR': 55,\n",
       " 'Hungary': 55,\n",
       " 'Iceland': 55,\n",
       " 'India': 55,\n",
       " 'Indonesia': 55,\n",
       " '\"Iran': 55,\n",
       " 'Iraq': 55,\n",
       " 'Ireland': 55,\n",
       " 'Isle of Man': 55,\n",
       " 'Israel': 55,\n",
       " 'Italy': 55,\n",
       " 'Jamaica': 55,\n",
       " 'Japan': 55,\n",
       " 'Jordan': 55,\n",
       " 'Kazakhstan': 55,\n",
       " 'Kenya': 55,\n",
       " 'Kiribati': 55,\n",
       " '\"Korea': 110,\n",
       " 'Kuwait': 52,\n",
       " 'Kyrgyz Republic': 55,\n",
       " 'Lao PDR': 55,\n",
       " 'Latvia': 55,\n",
       " 'Lebanon': 55,\n",
       " 'Lesotho': 55,\n",
       " 'Liberia': 55,\n",
       " 'Libya': 55,\n",
       " 'Liechtenstein': 55,\n",
       " 'Lithuania': 55,\n",
       " 'Luxembourg': 55,\n",
       " '\"Macao SAR': 55,\n",
       " '\"Macedonia': 55,\n",
       " 'Madagascar': 55,\n",
       " 'Malawi': 55,\n",
       " 'Malaysia': 55,\n",
       " 'Maldives': 55,\n",
       " 'Mali': 55,\n",
       " 'Malta': 55,\n",
       " 'Marshall Islands': 55,\n",
       " 'Mauritania': 55,\n",
       " 'Mauritius': 55,\n",
       " 'Mexico': 55,\n",
       " '\"Micronesia': 55,\n",
       " 'Moldova': 55,\n",
       " 'Monaco': 55,\n",
       " 'Mongolia': 55,\n",
       " 'Montenegro': 55,\n",
       " 'Morocco': 55,\n",
       " 'Mozambique': 55,\n",
       " 'Myanmar': 55,\n",
       " 'Namibia': 55,\n",
       " 'Nepal': 55,\n",
       " 'Netherlands': 55,\n",
       " 'New Caledonia': 55,\n",
       " 'New Zealand': 55,\n",
       " 'Nicaragua': 55,\n",
       " 'Niger': 55,\n",
       " 'Nigeria': 55,\n",
       " 'Northern Mariana Islands': 55,\n",
       " 'Norway': 55,\n",
       " 'Oman': 55,\n",
       " 'Pakistan': 55,\n",
       " 'Palau': 55,\n",
       " 'Panama': 55,\n",
       " 'Papua New Guinea': 55,\n",
       " 'Paraguay': 55,\n",
       " 'Peru': 55,\n",
       " 'Philippines': 55,\n",
       " 'Poland': 55,\n",
       " 'Portugal': 55,\n",
       " 'Puerto Rico': 55,\n",
       " 'Qatar': 55,\n",
       " 'Romania': 55,\n",
       " 'Russian Federation': 55,\n",
       " 'Rwanda': 55,\n",
       " 'Samoa': 55,\n",
       " 'San Marino': 55,\n",
       " 'Sao Tome and Principe': 55,\n",
       " 'Saudi Arabia': 55,\n",
       " 'Senegal': 55,\n",
       " 'Seychelles': 55,\n",
       " 'Sierra Leone': 55,\n",
       " 'Singapore': 55,\n",
       " 'Slovak Republic': 55,\n",
       " 'Slovenia': 55,\n",
       " 'Solomon Islands': 55,\n",
       " 'Somalia': 55,\n",
       " 'South Africa': 55,\n",
       " 'South Sudan': 55,\n",
       " 'Spain': 55,\n",
       " 'Sri Lanka': 55,\n",
       " 'St. Kitts and Nevis': 55,\n",
       " 'St. Lucia': 55,\n",
       " 'St. Vincent and the Grenadines': 55,\n",
       " 'Sudan': 55,\n",
       " 'Suriname': 55,\n",
       " 'Swaziland': 55,\n",
       " 'Sweden': 55,\n",
       " 'Switzerland': 55,\n",
       " 'Syrian Arab Republic': 55,\n",
       " 'Tajikistan': 55,\n",
       " 'Tanzania': 55,\n",
       " 'Thailand': 55,\n",
       " 'Timor-Leste': 55,\n",
       " 'Togo': 55,\n",
       " 'Tonga': 55,\n",
       " 'Trinidad and Tobago': 55,\n",
       " 'Tunisia': 55,\n",
       " 'Turkey': 55,\n",
       " 'Turkmenistan': 55,\n",
       " 'Turks and Caicos Islands': 55,\n",
       " 'Tuvalu': 55,\n",
       " 'Uganda': 55,\n",
       " 'Ukraine': 55,\n",
       " 'United Arab Emirates': 55,\n",
       " 'United Kingdom': 55,\n",
       " 'United States': 55,\n",
       " 'Uruguay': 55,\n",
       " 'Uzbekistan': 55,\n",
       " 'Vanuatu': 55,\n",
       " '\"Venezuela': 55,\n",
       " 'Vietnam': 55,\n",
       " 'Virgin Islands (U.S.)': 55,\n",
       " '\"Yemen': 55,\n",
       " 'Zambia': 55,\n",
       " 'Zimbabwe': 55,\n",
       " 'Serbia': 25,\n",
       " 'West Bank and Gaza': 25,\n",
       " 'Sint Maarten (Dutch part)': 17}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_dict = {}\n",
    "\n",
    "with open('../data/world_bank.csv') as file:\n",
    "    for line in read_large_file(file):\n",
    "        row = line.split(',')\n",
    "        first_col = row[0]\n",
    "\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "    \n",
    "counts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas' read_csv iterator for streaming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 CountryName CountryCode  Year  \\\n",
      "0                                 Arab World         ARB  1960   \n",
      "1                     Caribbean small states         CSS  1960   \n",
      "2             Central Europe and the Baltics         CEB  1960   \n",
      "3    East Asia & Pacific (all income levels)         EAS  1960   \n",
      "4      East Asia & Pacific (developing only)         EAP  1960   \n",
      "5                                  Euro area         EMU  1960   \n",
      "6  Europe & Central Asia (all income levels)         ECS  1960   \n",
      "7    Europe & Central Asia (developing only)         ECA  1960   \n",
      "\n",
      "   Total Population  Urban population (% of total)  \n",
      "0      9.249590e+07                      31.285384  \n",
      "1      4.190810e+06                      31.597490  \n",
      "2      9.140158e+07                      44.507921  \n",
      "3      1.042475e+09                      22.471132  \n",
      "4      8.964930e+08                      16.917679  \n",
      "5      2.653965e+08                      62.096947  \n",
      "6      6.674890e+08                      55.378977  \n",
      "7      1.553174e+08                      38.066129  \n",
      "                                      CountryName CountryCode  Year  \\\n",
      "8                                  European Union         EUU  1960   \n",
      "9        Fragile and conflict affected situations         FCS  1960   \n",
      "10         Heavily indebted poor countries (HIPC)         HPC  1960   \n",
      "11                                    High income         HIC  1960   \n",
      "12                           High income: nonOECD         NOC  1960   \n",
      "13                              High income: OECD         OEC  1960   \n",
      "14  Latin America & Caribbean (all income levels)         LCN  1960   \n",
      "15    Latin America & Caribbean (developing only)         LAC  1960   \n",
      "\n",
      "    Total Population  Urban population (% of total)  \n",
      "8        409498462.0                      61.212898  \n",
      "9        120354582.0                      17.891972  \n",
      "10       162491185.0                      12.236046  \n",
      "11       907597507.0                      62.680332  \n",
      "12       186676748.0                      56.107863  \n",
      "13       720920759.0                      64.285435  \n",
      "14       220564224.0                      49.284688  \n",
      "15       177682238.0                      44.863308  \n"
     ]
    }
   ],
   "source": [
    "df_reader = pd.read_csv('../data/world_bank.csv' , chunksize=8)\n",
    "print(next(df_reader))\n",
    "print(next(df_reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(91401583.0, 44.5079211390026),\n",
       " (92237118.0, 45.206665319194),\n",
       " (93014890.0, 45.866564696018),\n",
       " (93845749.0, 46.5340927663649),\n",
       " (94722599.0, 47.2087429803526)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urb_pop_reader = pd.read_csv('../data/world_bank.csv' , chunksize=1000)\n",
    "\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "pops = zip(df_pop_ceb['Total Population'], df_pop_ceb['Urban population (% of total)'])\n",
    "pop_list = list(pops)\n",
    "pop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "urb_pop_reader = pd.read_csv(\"../data/world_bank.csv\", chunksize=1000)\n",
    "\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop[\"CountryCode\"] == \"CEB\"]\n",
    "\n",
    "pops = zip(df_pop_ceb[\"Total Population\"], df_pop_ceb[\"Urban population (% of total)\"])\n",
    "pop_list = list(pops)\n",
    "\n",
    "df_pop_ceb.loc[:, \"Total Urban Population\"] = [\n",
    "    int(tup[0] * tup[1] * 0.01) for tup in pop_list\n",
    "]\n",
    "df_pop_ceb.plot(kind=\"scatter\", x=\"Year\", y=\"Total Urban Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urb_pop_reader = pd.read_csv(\"../data/world_bank.csv\", chunksize=1000)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for df_urb_pop in urb_pop_reader:\n",
    "    df_pop_ceb = df_urb_pop[df_urb_pop[\"CountryCode\"] == \"CEB\"]\n",
    "    pops = zip(df_pop_ceb[\"Total Population\"], df_pop_ceb[\"Urban population (% of total)\"])\n",
    "    pop_list = list(pops)\n",
    "    df_pop_ceb.loc[:, \"Total Urban Population\"] = [\n",
    "        int(tup[0] * tup[1] * 0.01) for tup in pop_list\n",
    "    ]\n",
    "    data = pd.concat([data, df_pop_ceb])\n",
    "\n",
    "data.plot(kind=\"scatter\", x=\"Year\", y=\"Total Urban Population\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pop(filename, country_code):\n",
    "    urb_pop_reader = pd.read_csv(filename, chunksize=1000)\n",
    "    data = pd.DataFrame()\n",
    "    for df_urb_pop in urb_pop_reader:\n",
    "        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]\n",
    "        pops = zip(df_pop_ceb['Total Population'],\n",
    "                    df_pop_ceb['Urban population (% of total)'])\n",
    "        pops_list = list(pops)\n",
    "\n",
    "        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]\n",
    "\n",
    "        data = pd.concat([data, df_pop_ceb])\n",
    "    data.plot(kind='scatter', x='Year', y='Total Urban Population')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "fn = 'ind_pop_data.csv'\n",
    "\n",
    "plot_pop('../data/world_bank.csv','CEB')\n",
    "plot_pop('../data/world_bank.csv','ARB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
